{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabafee1-eaf2-4a75-879a-4d4b9b3bcffc",
   "metadata": {},
   "source": [
    "# Topic:- Waste Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70703b4-ba30-4f82-92a7-3968064f9f0f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa7edc2-275d-48f2-81b1-fd996c0c7156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd #for manipulation and analysis\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for data visualization\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# For Grad-CAM\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Print versions (helps reproducibility)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7bb4c-dc8c-47b8-9a18-14e797ac916d",
   "metadata": {},
   "source": [
    "### Set the Path in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01c9583-30d6-4d7d-8c45-3cbf7ccff1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\js640\\Downloads\\archive (2)\\DATASET\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2444afa-58ed-462a-92e0-480d658c1886",
   "metadata": {},
   "source": [
    "### Load Training & Validation Data Using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a7093b-f2be-4f2c-9890-879e8ca40ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\js640\\\\Downloads\\\\archive (2)\\\\DATASET/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m IMG_SIZE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m      2\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m----> 4\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     12\u001b[0m     dataset_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mIMG_SIZE,\n\u001b[0;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     15\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:265\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, format, verbose)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 265\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:739\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 739\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m path_module\u001b[38;5;241m.\u001b[39misdir(path_module\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    741\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\js640\\\\Downloads\\\\archive (2)\\\\DATASET/train'"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir + \"/train\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir + \"/test\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bea36-b14d-4822-8945-b20176ae0a7a",
   "metadata": {},
   "source": [
    "### Print Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f27f03-5555-4692-8f4c-dc9cc2fd2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds.class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923974f1-5b10-4d32-bb16-358190196c19",
   "metadata": {},
   "source": [
    "### View Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d1817-d465-4959-a248-0f8470f86560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(train_ds.class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211457d-d089-4d60-abe8-3fa75b954f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save class names\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14deb6b8-96e8-4c2b-959f-1c72123311b3",
   "metadata": {},
   "source": [
    "### Build a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0add0b9-162a-4e5e-aa22-169cba698b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(224, 224, 3)),  # Normalize\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='softmax'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='softmax'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='softmax'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='softmax'),\n",
    "    tf.keras.layers.Dense(len(train_ds.class_names), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1378def-3936-489c-a730-8afa34aebf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef94ff-bd85-41d3-a0b4-b2ee7e020e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce83a8-1163-4b68-96e9-7dd7550efcc1",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f1db3-b87c-4921-b0b8-146d7ba7a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3826fd-5f6d-4153-ba0d-60910d0a46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Validation accuracy:\", accuracy)\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e16de3-6d40-4c18-a93d-e81e58cc748a",
   "metadata": {},
   "source": [
    "### Training Accuracy/Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149485b-9aba-42ce-a277-23d4e68881aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d4e11-ec08-4cc1-95b3-d1aa84c38877",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\js640\\Downloads\\archive (2)\\DATASET\\TEST\\R\\R_10938.jpg\"\n",
    "#print(os.listdir(img_path))\n",
    "img = tf.keras.utils.load_img(img_path, target_size=IMG_SIZE)\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
    "\n",
    "pred = model.predict(img_array)\n",
    "class_id = np.argmax(pred)\n",
    "class_name = train_ds.class_names[class_id]\n",
    "\n",
    "print(\"Predicted class:\", class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8c8a2-53c9-45e3-8073-db6779e46fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\js640\\Downloads\\archive (2)\\DATASET\\TEST\\R\"\n",
    "print(os.listdir(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8aeeea-5940-44be-91a3-72fe3bada0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83208536-04e4-400e-bfa8-1e9626bcc3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all images and labels from val_ds\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d845d-e4e5-442c-9a26-d94d41f6b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e2c25-ab45-474e-877f-51701f6acc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbad40-ca58-41d6-94a2-cc32df45b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder \n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def show_predictions(n=9):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    i = 0\n",
    "    for images, labels in test_ds.take(5):\n",
    "        preds = model.predict(images)\n",
    "        for j in range(images.shape[0]):\n",
    "            if i >= n: break\n",
    "            ax = plt.subplot(3,3,i+1)\n",
    "            img = images[j].numpy()\n",
    "            img = (img - img.min())/(img.max()-img.min())\n",
    "            plt.imshow(img)\n",
    "            true = class_names[int(labels[j])]\n",
    "            pred = class_names[int(np.argmax(preds[j]))]\n",
    "            plt.title(f\"T:{true}\\nP:{pred}\")\n",
    "            plt.axis('off')\n",
    "            i += 1\n",
    "        if i >= n: break\n",
    "    plt.suptitle(\"Sample predictions\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"pred_examples.png\"))\n",
    "    plt.show()\n",
    "\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bfdb3-dc04-4b41-9540-27e755eb3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder \n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def show_predictions(n=9):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    i = 0\n",
    "    for images, labels in test_ds.take(1):\n",
    "        preds = model.predict(images)\n",
    "        for j in range(images.shape[0]):\n",
    "            if i >= n: break\n",
    "            ax = plt.subplot(3,3,i+1)\n",
    "\n",
    "            img = images[j].numpy()\n",
    "            img = (img - img.min())/(img.max() - img.min())\n",
    "            plt.imshow(img)\n",
    "\n",
    "            true = class_names[int(labels[j])]\n",
    "            pred = class_names[int(np.argmax(preds[j]))]\n",
    "\n",
    "            plt.title(f\"T:{true}\\nP:{pred}\")\n",
    "            plt.axis('off')\n",
    "            i += 1\n",
    "\n",
    "    plt.suptitle(\"Sample predictions\")\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"pred_examples.png\"))\n",
    "    plt.show()\n",
    "\n",
    "show_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552355a-8f83-40f3-a0f6-f98948afa7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "class_names = [\"organic\", \"recyclable\"]\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=(224,224))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array / 255.0, axis=0)  # Normalize\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    class_id = np.argmax(prediction[0])\n",
    "    return class_names[class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ac69e-0cd7-46a8-b703-046d8bb01876",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_image(test_dir + \"\\O\\\\O_12568.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f75aae-e20e-4907-b5be-78c098a01210",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad7257-48b0-488a-aea2-e79d70b12ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"waste_classifier.h5\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573fbf8-fb33-4911-8195-1375c888fff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
